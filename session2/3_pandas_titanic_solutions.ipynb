{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas et scikit-learn\n",
    "\n",
    "## Données du titanic (challenge Kaggle)\n",
    "\n",
    "Camille Marini  \n",
    "Repris d'un notebook d'Alexandre Gramfort donné pour un workshop Python sur [\"Predictive Modeling with scikit-learn and pandas\"](https://github.com/camillemarini/sklearn_pandas_intro).\n",
    "\n",
    "Pour cette session, nous allons utiliser [pandas](http://pandas.pydata.org/), une librairie qui permet de manier facilement des données, et [sklearn](http://scikit-learn.org/stable/), une librairie de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données dans un DataFrame pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser le jeu de données du challenge Kaggle sur la prédiction de la survie à bord du Titanic:\n",
    "https://www.kaggle.com/c/titanic-gettingStarted\n",
    "\n",
    "Pour télécharger les données: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/6wu5fwj1i6cju2i/titanic_train.csv?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour charger le fichier csv dans un DataFrame pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('https://www.dropbox.com/s/6wu5fwj1i6cju2i/titanic_train.csv?dl=0')\n",
    "data = pd.read_csv('titanic_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les DataFrames pandas sont affichés dans des tableaux html dans les jupyter notebook. Regardons les 5 premières lignes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différentes données sont expliquées sur le site du challenge:\n",
    "\n",
    "https://www.kaggle.com/c/titanic-gettingStarted/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le DataFrame a 891 lignes. Il manque des données pour certains passagers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut convertir un DataFrame en un numpy array avec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème est qu'on ne peut pas directement donner ce DataFrame comme entrée d'un modèle scikit-learn, car:\n",
    "\n",
    "* la variable cible (`Survived`) est avec les variables d'entrée  \n",
    "* certains attributs comme les ids (`PassengerId`) n'ont aucune valeur prédictive.  \n",
    "* Les données sont hétérogènes: string et des nombres.  \n",
    "* certaines données sont manquantes (`nan`: \"not a number\")  \n",
    "\n",
    "On va utiliser pandas pour préparer ces données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédire la survie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but du challenge est de prévoir si un passager a survécu à partir d'autres attributs connus. Commençons par regarder la colonne `Survived`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_column = data['Survived']\n",
    "survived_column.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data.Survived` est une instance de la classe `Series` de pandas avec un dtype integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(survived_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` est une instance de la classe `DataFrame` de pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les instances de `Series` correspondent à des données 1D homogènes, alors que les instances de `DataFrame` sont des collections hétérogènres de colonnes de même longueur. \n",
    "\n",
    "Le DataFrame original peut être aggrégé en comptant les lignes pour chaque valeur possible de la variable `Survived`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(survived_column == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ces données, 62% des passagers ont péri (68% sur l'ensemble des passagers). On peut choisir comme modèle de référence un modèle qui prédirait constamment la non survie du passager. Il aurait une accuracy de 62% (ce qui est plus grand que le hasard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut convertir les instances `Series` de pandas en un 1D numpy arrays en utilisant l'attribut `values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = survived_column.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner un modèle prédictif sur des features numériques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les estimateurs `sklearn` acceptent des features numériques passées comme un numpy array. On ne peut donc pas passer le DataFrame brut. \n",
    "\n",
    "On commence simplement en construisant un modèle qui utilise seulement les features numériques données telles quelles: `data.Fare`, `data.Pclass` et `data.Age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
    "numerical_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malheureusement, il manque l'âge de certains passagers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut utiliser la méthode `fillna` de pandas pour remplacer les `nan` par l'âge médian des passagers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_features = numerical_features.dropna().median()\n",
    "median_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_features = numerical_features.fillna(median_features)\n",
    "imputed_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le DataFrame est propre, on peut le convertir en un numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = imputed_features.values\n",
    "features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons 80% des données pour l'entraînement et gardons 20% pour calculer le score de généralisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_array, target, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons avec un modèle simple de sklearn: [sklearn.linear_model.LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "**Question**:\n",
    "* Calculer les prédictions du modèle  \n",
    "* Calculer l'accuracy de notre modèle. Est ce mieux que le modèle de référence qui prédit toujours la non survie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C=1.)\n",
    "logreg.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted = logreg.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(target_test, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre premier modèle a une accuracy de 73%. C'est mieux que notre modèle de référence qui prédit toujours la non survie!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du modèle et interprétation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpréter les poids du modèle linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'attribut `coef_` d'un modèle linéaire entraîné (tel que `LogisticRegression`) contient les poids de chaque feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = numerical_features.columns\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(feature_names))\n",
    "plt.bar(x, logreg.coef_.ravel())\n",
    "_ = plt.xticks(x + 0.5, feature_names, rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notrre modèle, le `Fare` a une influence positive sur la survie, tandis que la `Pclass` et l'`Age` ont une influence négative. \n",
    "\n",
    "Les cabines de premières classes étaient plus proches des canots de sauvetage et que les femmes et enfants étaient évacués en priorité. Notre modèle semble capturer ces données historiques! On verra plus tard si le sexe des passagers est une information utilse pour augmenter les performances de notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthodes d'évaluation alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut utiliser la matrice de confusion pour obtenir les détails des faux positifs et faux négatifs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(target_test, target_predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les vraies étiquettes correspondent aux lignes et les prédites aux colonnes.\n",
    "\n",
    "**Question**:\n",
    "* faire un plot de la matrice de confusion  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(cm):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.binary)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.set_cmap('Blues')\n",
    "    plt.colorbar()\n",
    "\n",
    "    target_names = ['not survived', 'survived']\n",
    "\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=60)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    # Convenience function to adjust plot parameters for a clear layout.\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_confusion(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut normaliser le nombre de prédiction en divisant par le nombre total de vrais `survived` et `not survived` pour calculer les taux de faux et vrais postifs pour la survie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)\n",
    "cm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.astype(np.float64) / cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que comme le jeu de données n'est pas balancé (peu de cas de survie par rapport à la non survie), le score d'accuracy n'est pas très informatif: il est assez bon, alors qu'on arrive très mal à prédire les cas de survie. \n",
    "\n",
    "On peut utiliser d'autres métriques pour évaluer la performance des modèles pour les jeux de données non balancés: precision, recall et le f1-score.\n",
    "\n",
    "**Question**:\n",
    "* Calculer ces métriques en utilisant les fonctions de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(target_test, target_predicted,\n",
    "                            target_names=['not survived', 'survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La régression logistique est un modèle probabiliste: il ne prédit pas qu'un output binaire (survived or not), mais il estime une probabilité que l'on peut obtenir avec la méthode `predict_proba`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted_proba = logreg.predict_proba(features_test)\n",
    "target_predicted_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défault, la seuil de décision est à 0.5. Si on varie ce seuil de 0 à 1, on peut générer une famille de classifieurs binaires qui correspondent à différents compromis entre les taux de faux positifs et faux négatifs.\n",
    "\n",
    "On peut résumer les performances de cette famille en plottant la courbe ROC et en calculant l'AUC (Area Under the Curve).\n",
    "\n",
    "**Question**:\n",
    "* en utilisant `sklearn.metrics.roc_curve` et `sklearn.metrics.auc`, dessiner cette courbe et afficher la valeur de l'AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_curve(target_test, target_predicted_proba):\n",
    "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or or recall or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(target_test, target_predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, l'AUC vaut 0.756, ce qui est similaire à l'accuracy de notre modèle (0.732).   \n",
    "L'AUC d'un modèle random vaut 0.5, tandis que l'accuracy est influencé par le fait que le jeu de données n'est pas bien balancé. L'AUC peut être vue comme une façon de calibrer l'accuracy d'un modèle en prenant en compte le fait que le jeu de données n'est pas bien balancé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est important de faire de la validation croisée pour évaluer notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "\n",
    "- Calculer les scores \"cross-validés\" pour différentes métriques ('AUC', 'precision', 'recall', 'f1', 'accuracy'...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(logreg, features_array, target, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(logreg, features_array, target, cv=5,\n",
    "                         scoring='roc_auc')\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3, 11):\n",
    "    %time scores = cross_val_score(logreg, features_array, target, cv=k, scoring='roc_auc')\n",
    "    print(scores.min(), scores.mean(), scores.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner un modèle prédictif sur des features plus complexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant essayer de construire des modèles plus riches en incluant plus de features. \n",
    "\n",
    "Les variables catégorielles, telles que `data.Embarked` ou `data.Sex` peuvent être converties comme des booléens, appelés \"dummy variables\" ou \"one-hot-encoded features\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data.Sex, prefix='Sex').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data.Embarked, prefix='Embarked').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: \n",
    "* Combiner ces nouvelles variables numériques avec les précédentes features dans un pandas DataFrame (appelé `rich_features`) en utilisant `pandas.concat`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_features = pd.concat([data.get(['Fare', 'Pclass', 'Age']),\n",
    "                           pd.get_dummies(data.Sex, prefix='Sex'),\n",
    "                           pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
    "                          axis=1)\n",
    "rich_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par construction, la nouvelle feature `Sex_male` est redondante avec  `Sex_female`. On peut l'enlever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_features_no_male = rich_features.drop('Sex_male', 1)\n",
    "rich_features_no_male.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N'oublions pas d'imputer la valeur d'âge médian pour les passagers sans information d'âge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_features_no_male.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_features_final = rich_features_no_male.fillna(rich_features_no_male.dropna().median())\n",
    "rich_features_final.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "* Calculer les scores \"cross-validés\" d'un modèle de régression logistique utilisant ces nouvelles features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logreg = LogisticRegression(C=1.)\n",
    "scores = cross_val_score(logreg, rich_features_final, target, cv=5, scoring='accuracy')\n",
    "print(\"Logistic Regression CV scores:\")\n",
    "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
    "    scores.min(), scores.mean(), scores.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "\n",
    "* Afficher les poids des features de ce nouveau modèle de régression logistique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_new = LogisticRegression(C=1).fit(rich_features_final, target)            \n",
    "                                                                                 \n",
    "feature_names = rich_features_final.columns.values                               \n",
    "x = np.arange(len(feature_names))                                                \n",
    "plt.bar(x, logreg_new.coef_.ravel())                                             \n",
    "_ = plt.xticks(x + 0.5, feature_names, rotation=30)                              \n",
    "                                                                                 \n",
    "# Rich young women like Kate Winslet tend to survive the Titanic better          \n",
    "# than poor men like Leonardo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser les pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand on a rempli les valeurs manquantes par les valeurs médianes (imputation) avant de calculer les ensembles de train et de test, on utilise des données de test, ce qui est tricher...\n",
    "\n",
    "Pour éviter cela, on devrait calculer les valeurs médianes seulement sur les données d'éntraînement et imputer ces valeurs à la fois sur les données d'entraînement et de test.\n",
    "\n",
    "Pour cela, on peut préparer les features comme précédemment mais sans l'imputation, puis on utilise `sklearn.preprocessing.Imputer` pour calculer les valeurs médianes sur l'ensemble d'entraînement et les imputer aux valeurs manquantes sur l'ensemble d'entraînement et de test. On utilise enfin un `sklearn.pipeline.Pipeline` pour mettre tout ça ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([data.get(['Fare', 'Age']),\n",
    "                      pd.get_dummies(data.Sex, prefix='Sex'),\n",
    "                      pd.get_dummies(data.Pclass, prefix='Pclass'),\n",
    "                      pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
    "                     axis=1)\n",
    "features = features.drop('Sex_male', 1)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features.values, target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(strategy='median', missing_values=\"NaN\")\n",
    "\n",
    "imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs médianes sont enregistrées dans l'attribut `statistics_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'imputation se fait en appellant la méthode `transform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed = imputer.transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise maintenant un pipeline pour combiner l'imputation et le classifieur: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "imputer = Imputer(strategy='median', missing_values=\"NaN\")\n",
    "\n",
    "classifier = LogisticRegression(C=1.)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imp', imputer),\n",
    "    ('clf', classifier),\n",
    "])\n",
    "\n",
    "scores = cross_val_score(pipeline, features.values, target, cv=5, n_jobs=4,\n",
    "                         scoring='accuracy', )\n",
    "print(scores.min(), scores.mean(), scores.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crédits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merci à:\n",
    "* Alexandre Gramfort pour ce notebook  \n",
    "* Kaggle pour la mise en place de ce challenge Titanic  \n",
    "* Ce blog post de Philippe Adjiman dont s'est inspiré A. Gramfort:\n",
    "http://www.philippeadjiman.com/blog/2013/09/12/a-data-science-exploration-from-the-titanic-in-r/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
